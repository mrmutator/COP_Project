\section{Related Work}\label{sec:relwork}
Several approaches have been proposed for classifying dialog acts. Most of them rely on supervised trained models, and use hand crafted features extracted for all utterances. Some recent work shows that using distributional representations for dialog act classification outperforms these methods. We briefly present some of the most relevant work in this section.

The authors of \newcite{stolcke2000} predict dialog acts by modeling a conversation as a Hidden Markov Model (HMM). A sequence of dialog acts is represented as a \emph{discourse model} where the probability of the next dialog act depends on the \emph{n} previous dialog acts. They integrate this model with a \emph{language model} for each separate dialog act, which computes the possibility of the occurrence of all \emph{word n-grams} in an utterance given a certain dialog act tag. In \newcite{stolcke2000} models are also trained on the actual speech signals, where the `language model' is trained on prosodic and acoustic evidence. When considering the models trained on the dialog transcripts we can see that in this an utterance is represented as a bag of n-grams. We aim to find a single model to directly find the dialog act of an utterance given some representation.
%We will try to find a representation that captures the composition of an utterance in a better way

In \newcite{kalchbrenner} a Recurrent Convolutional Neural Network (RCNN) is trained in a supervised manner on a corpus, which achieves state of the art results on the dialog act tagging task. The RCNN learns both a \emph{discourse model} and a \emph{sentence model} from a specific corpus, where the utterance representation is derived from individual word vectors, which are chosen randomly. We feel that this representation can become a lot richer if it is learned as in \newcite{le2014distributed}, where word vectors have some distributional meaning. Another strength of this approach is that it is possible to train these utterance embeddings in an unsupervised manner, making it possible to additional, possibly unannotated, corpora. 

An investigation on the contribution of distributional semantic information to the dialog act tagging task was conducted in \newcite{milajevs}. It was found that such information did improve tagging when compared to simple bag of words approaches. However only very simple distributional representations were investigated in this research, words were represented as a vector of their co-occurrences. Utterances as point wise multiplications or additions of these vectors, which implicates the loss of any compositional features. The work of \newcite{milajevs} was not able to outperform the earlier work on dialog act tagging presented before. We believe that with richer representations of utterances, where we also incorporate composition, that we can improve on this performance.

%In our work we will use the same \emph{discourse model} as \newcite{stolcke2000} and represent the entire dialog as an HMM. However for our \emph{sentence model} we will train different classifiers based on the embeddings, which are learned using the techniques from \newcite{le2014distributed}. We will explain how we construct utterance embeddings in the next section. In section \ref{sec:method} we explain how we use these representations to build a \emph{sentence model} as well and briefly repeat the \emph{discourse model} as an HMM.

We will attempt to find a model that directly models the probability of dialog tags given a representation of an utterance. Unlike \newcite{stolcke2000} who learn a separate model for the dialog and for each dialog act. We will adopt techniques proposed by \newcite{le2014distributed}, which we will explain in the next section, to capture the words and composition of an utterance. Just like \newcite{milajevs} we will use these rich representations to train classifiers. Note that we will not only model context by or concatenating utterance representations and leave a more informative approach to future work.