\begin{abstract}
%	\begin{itemize}
%		\item Dialog act (tagging)
%		\item Word/sentence embedding
%		\item Our research in one sentence
%		\item Results and compare to others
%		\item ...
%	\end{itemize}
In this work, we experiment with a new feature representation for dialog act tagging by learning distributional embeddings for utterances. We train a distributional semantic model that allows us to infer vector representations for entire utterances in an unsupervised fashion and use them to train several classifiers in order to tag utterances in the Switchboard corpus. 
%\lau{add something about results}
\end{abstract}
