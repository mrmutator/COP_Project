\begin{abstract}
%	\begin{itemize}
%		\item Dialog act (tagging)
%		\item Word/sentence embedding
%		\item Our research in one sentence
%		\item Results and compare to others
%		\item ...
%	\end{itemize}
Traditionally, automatic Dialog Act Tagging has been based on training machine learning classifiers using hand-crafted features extracted from data.
In this work, we experiment with a new feature representation for dialog act tagging by learning distributional embeddings for utterances. We train a distributional semantic model that allows us to infer vector representations for entire utterances and use them to train several classifiers in order to tag utterances in the Switchboard corpus.
%\lau{add something about results}
\end{abstract}