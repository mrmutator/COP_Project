\section{Conclusion}\label{sec:conclusion}
We see that all models trained on utterance embeddings found with the techniques from \newcite{le2014distributed} outperform the trivial baseline of predicting the most frequent tag. This supports the hypothesis that such distributional representations can be used successfully for dialog act tagging.

However a simple model using a bag of words representation and a Naive Bayes classifier outperforms these more intricate representations and models. \david{why is this? because of the short utterances? seems strange...}

Moreover we see that training the utterance embeddings with extra samples from the BNC does not have a big effect on the accuracy of the classifiers. This could be explained by the fact that the utterances in the BNC have been cleaned to be more like grammatically correct sentences, where the SwDA is in comprised of more accurately transcribed utterances. Therefore we recommend future work to use additional data that is more similar to the data used in training and evaluating the classifier. In order to investigate whether this increases the accuracy of the tagging.

When comparing the results of the classifiers on a coarser tag set we see that the accuracy dramatically increases for all classifiers. This shows that the classifiers make most mistakes confusing dialog acts that are closely related. \david{I don't know if this is true, but it would make sense, maybe support the claim with a confusion matrix?}

Perhaps the most prominent deficiency of the approach presented in this paper is the lack of naturally incorporating context into the utterance representation. Using only the previous utterance is not enough to model the context of the current utterance. Even though this behaviour was to be expected, it is surprising that aggregating the previous embedding (either by concatenation or addition) did not improve accuracy.\david{Can somebody check this?} Future work should therefore mainly concentrate on mending this weakness. One possible approach to this problem would be to use yet another deep learning neural network technique called Long Short Term Memory (LSTM) as proposed by \newcite{lstm-original}. This recurrent neural network uses a so called memory cell with four connections, an input gate, an output gate, a self recurrent gate and a forget gate. The input gate can be used to alter the state of the memory cell, while the output gate can be used to affect the state of other layers. This technique can be applied to dialog act tagging by using the utterance embeddings presented earlier as inputs for the LSTM. The output of the LSTM cell can then be used to predict a tag for that utterance. Since the utterances are fed to the LSTM in sequence, the memory cell can be thought to represent the contextual knowledge of the conversation up to that point.

\david{are we missing anything?}
\david{some general conclusion to wrap it all up here.}